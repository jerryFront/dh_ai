{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "---\n",
      "conv1.0.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.0.bias torch.Size([6])\n",
      "conv2.0.weight torch.Size([16, 6, 5, 5])\n",
      "conv2.0.bias torch.Size([16])\n",
      "fc1.0.weight torch.Size([120, 256])\n",
      "fc1.0.bias torch.Size([120])\n",
      "fc2.0.weight torch.Size([84, 120])\n",
      "fc2.0.bias torch.Size([84])\n",
      "fc3.weight torch.Size([10, 84])\n",
      "fc3.bias torch.Size([10])\n",
      "total parameters: 44426\n",
      "input x to model: torch.Size([64, 1, 28, 28])\n",
      "conv1 after size: torch.Size([64, 6, 12, 12])\n",
      "conv2 after size: torch.Size([64, 16, 4, 4])\n",
      "fc1 after size: torch.Size([64, 120])\n",
      "fc2 after size: torch.Size([64, 84])\n",
      "fc3 after size: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 1, 28, 28)\n",
    "        conv1: (1, 28, 28) -> (6, 24, 24) -> (6, 12, 12)\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 6, 12, 12)\n",
    "        conv2: (6, 12, 12) -> (16, 8, 8) -> (16, 4, 4)\n",
    "        \"\"\"\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 16, 4, 4)\n",
    "        fc1: (16, 4, 4) -> (120,)\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 120),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 120)\n",
    "        fc2: (120,) -> (84,)\n",
    "        \"\"\"\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 84)\n",
    "        fc3: (84,) -> (10,)\n",
    "        \"\"\"\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 1, 28, 28)\n",
    "        \"\"\"\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 1, 28, 28)\n",
    "        conv1: (1, 28, 28) -> (6, 24, 24) -> (6, 12, 12)\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 6, 12, 12)\n",
    "        conv2: (6, 12, 12) -> (16, 8, 8) -> (16, 4, 4)\n",
    "        \"\"\"\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        \"\"\"\n",
    "        flatten\n",
    "        input shape: (batch_size, 16, 4, 4)\n",
    "        output shape: (batch_size, 16*4*4)\n",
    "        \"\"\"\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 16*4*4)\n",
    "        fc1: (16*4*4) -> (120,)\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 120)\n",
    "        fc2: (120,) -> (84,)\n",
    "        \"\"\"\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 84)\n",
    "        fc3: (84,) -> (10,)\n",
    "        \"\"\"\n",
    "        output = self.fc3(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            prob_list = prob.squeeze().tolist()\n",
    "            prob, index = torch.max(prob, 1)\n",
    "        return index, prob, prob_list\n",
    "\n",
    "\n",
    "def print_params(model):\n",
    "    count = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        count += param.numel()\n",
    "        print(name, param.shape)\n",
    "    print('total parameters:', count)\n",
    "\n",
    "\n",
    "def print_forward(model, x):\n",
    "    print('input x to model:', x.shape)\n",
    "    for name, layer in model.named_children():\n",
    "        if name == 'fc1':\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        x = layer(x)\n",
    "        print(f'{name} after size: {x.shape}')\n",
    "\n",
    "\n",
    "test_model = LeNet()\n",
    "print(test_model)\n",
    "print('---')\n",
    "print_params(test_model)\n",
    "\n",
    "x = torch.randn(64, 1, 28, 28)\n",
    "print_forward(test_model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:37<00:00, 261305.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 116849.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 861570.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1844015.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 设置全局随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(seed + worker_id)\n",
    "    random.seed(seed + worker_id)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(12),  # 随机旋转 12 度\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载训练数据集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# 定义训练数据加载器\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=64, shuffle=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "model = LeNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def calculate_test_performance(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() * len(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/honglei.wu/Desktop/机器学习/code/dh_ai/week10-卷积神经网络/wandb/run-20240905_103532-tqkmry0t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/tqkmry0t' target=\"_blank\">glorious-forest-43</a></strong> to <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/tqkmry0t' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/tqkmry0t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.3133\n",
      "Epoch [1/10], Step [200/938], Loss: 0.1929\n",
      "Epoch [1/10], Step [300/938], Loss: 0.3780\n",
      "Epoch [1/10], Step [400/938], Loss: 0.2173\n",
      "Epoch [1/10], Step [500/938], Loss: 0.1584\n",
      "Epoch [1/10], Step [600/938], Loss: 0.0541\n",
      "Epoch [1/10], Step [700/938], Loss: 0.1795\n",
      "Epoch [1/10], Step [800/938], Loss: 0.2038\n",
      "Epoch [1/10], Step [900/938], Loss: 0.0446\n",
      "Epoch [2/10], Step [100/938], Loss: 0.0786\n",
      "Epoch [2/10], Step [200/938], Loss: 0.0610\n",
      "Epoch [2/10], Step [300/938], Loss: 0.1948\n",
      "Epoch [2/10], Step [400/938], Loss: 0.1099\n",
      "Epoch [2/10], Step [500/938], Loss: 0.0588\n",
      "Epoch [2/10], Step [600/938], Loss: 0.1006\n",
      "Epoch [2/10], Step [700/938], Loss: 0.0563\n",
      "Epoch [2/10], Step [800/938], Loss: 0.1009\n",
      "Epoch [2/10], Step [900/938], Loss: 0.1376\n",
      "Epoch [3/10], Step [100/938], Loss: 0.0234\n",
      "Epoch [3/10], Step [200/938], Loss: 0.1687\n",
      "Epoch [3/10], Step [300/938], Loss: 0.0203\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0308\n",
      "Epoch [3/10], Step [500/938], Loss: 0.1436\n",
      "Epoch [3/10], Step [600/938], Loss: 0.0017\n",
      "Epoch [3/10], Step [700/938], Loss: 0.0453\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0805\n",
      "Epoch [3/10], Step [900/938], Loss: 0.0751\n",
      "Epoch [4/10], Step [100/938], Loss: 0.0824\n",
      "Epoch [4/10], Step [200/938], Loss: 0.0176\n",
      "Epoch [4/10], Step [300/938], Loss: 0.0829\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0288\n",
      "Epoch [4/10], Step [500/938], Loss: 0.0448\n",
      "Epoch [4/10], Step [600/938], Loss: 0.0284\n",
      "Epoch [4/10], Step [700/938], Loss: 0.0769\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0271\n",
      "Epoch [4/10], Step [900/938], Loss: 0.0245\n",
      "Epoch [5/10], Step [100/938], Loss: 0.1031\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0156\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0106\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0488\n",
      "Epoch [5/10], Step [500/938], Loss: 0.0106\n",
      "Epoch [5/10], Step [600/938], Loss: 0.0491\n",
      "Epoch [5/10], Step [700/938], Loss: 0.0173\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0341\n",
      "Epoch [5/10], Step [900/938], Loss: 0.0648\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0098\n",
      "Epoch [6/10], Step [200/938], Loss: 0.0060\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0369\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0624\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0637\n",
      "Epoch [6/10], Step [600/938], Loss: 0.3613\n",
      "Epoch [6/10], Step [700/938], Loss: 0.0266\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0826\n",
      "Epoch [6/10], Step [900/938], Loss: 0.0867\n",
      "Epoch [7/10], Step [100/938], Loss: 0.0207\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0026\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0090\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0854\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0463\n",
      "Epoch [7/10], Step [600/938], Loss: 0.0120\n",
      "Epoch [7/10], Step [700/938], Loss: 0.0093\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0164\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0112\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0017\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0146\n",
      "Epoch [8/10], Step [300/938], Loss: 0.1231\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0414\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0797\n",
      "Epoch [8/10], Step [600/938], Loss: 0.0342\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0211\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0022\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0267\n",
      "Epoch [9/10], Step [100/938], Loss: 0.0045\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0398\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0146\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0021\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0477\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0115\n",
      "Epoch [9/10], Step [700/938], Loss: 0.0038\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0247\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0171\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0448\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0247\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0059\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0263\n",
      "Epoch [10/10], Step [500/938], Loss: 0.0189\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0049\n",
      "Epoch [10/10], Step [700/938], Loss: 0.0700\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0017\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>test_accuracy</td><td>▁▅▆▆▇████▇</td></tr><tr><td>test_loss</td><td>█▄▃▂▁▁▁▁▁▂</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>test_accuracy</td><td>0.9881</td></tr><tr><td>test_loss</td><td>0.03736</td></tr><tr><td>train_accuracy</td><td>0.98922</td></tr><tr><td>train_loss</td><td>0.03193</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-forest-43</strong> at: <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/tqkmry0t' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/tqkmry0t</a><br/> View project at: <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240905_103532-tqkmry0t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.require(\"core\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "total = len(train_loader.dataset)  # type: ignore\n",
    "epochs = 25\n",
    "\n",
    "wandb_init_args = {\n",
    "    'project': 'MNIST-手写数字识别',\n",
    "    'config': {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": \"LeNet-5\",\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    "    'reinit': True\n",
    "}\n",
    "run = wandb.init(**wandb_init_args, job_type=\"training\")\n",
    "wandb_init_args['name'] = run.name\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    test_loss, test_accuracy = calculate_test_performance(\n",
    "        model, test_loader, criterion)\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss / total,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"train_accuracy\": train_correct / total,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/14nkpqsn4zs8c1dmkl0p4mxr0000gp/T/ipykernel_65232/703398484.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet()\n",
    "model.load_state_dict(torch.load(\n",
    "    './model.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2, 1: 4, 2: 4, 3: 9, 4: 13, 5: 10, 6: 12, 7: 15, 8: 6, 9: 12}\n",
      "error-count: 87\n",
      "Accuracy of the network on the 10000 test images: 99.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 测试模型\n",
    "model.eval()  # 切换到评估模式\n",
    "with torch.no_grad():\n",
    "    \"\"\" 统计每个数字的错误次数 \"\"\"\n",
    "    error_count_dict = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 0,\n",
    "        5: 0,\n",
    "        6: 0,\n",
    "        7: 0,\n",
    "        8: 0,\n",
    "        9: 0\n",
    "    }\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_index, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error_index = np.where((predicted == labels).cpu().numpy() == False)[0]\n",
    "        for index in error_index:\n",
    "            error_count_dict[labels[index].item()] += 1\n",
    "\n",
    "test_loss /= total\n",
    "test_accuracy = correct / total\n",
    "\n",
    "pprint(error_count_dict)\n",
    "print('error-count:', sum(error_count_dict.values()))\n",
    "print('Accuracy of the network on the 10000 test images: {:.2f}%'.format(\n",
    "    100 * test_accuracy))\n",
    "\n",
    "# 将每个数字的错误次数绘制为柱状图\n",
    "plt.bar(error_count_dict.keys(), error_count_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存后加载模型\n",
    "torch.save(model.state_dict(), './model.pth')\n",
    "\n",
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('./server/model.pth'))\n",
    "\n",
    "# # 创建一个示例输入张量（假设输入尺寸是 [1, 784]）\n",
    "# dummy_input = torch.randn(1, 28 * 28)\n",
    "\n",
    "# # 导出模型到 ONNX 格式\n",
    "# torch.onnx.export(\n",
    "#     model,                # 要转换的模型\n",
    "#     dummy_input,          # 示例输入张量\n",
    "#     \"model.onnx\",         # 导出的 ONNX 文件名\n",
    "#     input_names=['input'],  # 输入张量的名称\n",
    "#     output_names=['output'],  # 输出张量的名称\n",
    "#     opset_version=11      # ONNX opset 版本，通常使用最新版本（这里使用 11）\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0835, -0.1147,  0.1766, -0.2374, -0.3184],\n",
      "          [ 0.2185, -0.0712,  0.3234, -0.1315, -0.4185],\n",
      "          [ 0.0095,  0.0825,  0.3548,  0.1549, -0.4919],\n",
      "          [-0.1100,  0.1137,  0.3204,  0.2863,  0.1132],\n",
      "          [-0.3496, -0.0276,  0.1008,  0.2028,  0.1251]]],\n",
      "\n",
      "\n",
      "        [[[-0.0621,  0.1024, -0.4355, -0.3109, -0.3119],\n",
      "          [-0.0978, -0.3006, -0.1599, -0.2412, -0.0855],\n",
      "          [ 0.0588, -0.1527,  0.1515,  0.0362,  0.0635],\n",
      "          [ 0.3056,  0.2454,  0.3532,  0.5081,  0.3636],\n",
      "          [-0.0525,  0.1815, -0.0728, -0.1059,  0.0304]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0142,  0.1986,  0.1604,  0.4141,  0.1842],\n",
      "          [ 0.0671,  0.0861,  0.2015,  0.1312,  0.5027],\n",
      "          [-0.2690, -0.1346,  0.1009, -0.1540,  0.0628],\n",
      "          [ 0.0016, -0.0773, -0.3285, -0.2970, -0.3599],\n",
      "          [-0.1304, -0.0544, -0.2001, -0.1619, -0.1192]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1370,  0.3224,  0.1260,  0.0338, -0.1960],\n",
      "          [ 0.3016,  0.1885, -0.0062, -0.3448, -0.3195],\n",
      "          [ 0.2000,  0.3156, -0.0808, -0.4459, -0.3927],\n",
      "          [ 0.1937,  0.0829, -0.2539, -0.3234, -0.3097],\n",
      "          [ 0.1998, -0.0258, -0.0285, -0.2007,  0.0049]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1293,  0.0082, -0.2017, -0.0877,  0.0146],\n",
      "          [-0.1708, -0.1028, -0.0638,  0.1904,  0.1517],\n",
      "          [ 0.0062,  0.2050,  0.3088,  0.2905,  0.1059],\n",
      "          [ 0.0044,  0.4221,  0.1561, -0.2197, -0.2859],\n",
      "          [-0.0078, -0.0156, -0.3512, -0.3174, -0.0434]]],\n",
      "\n",
      "\n",
      "        [[[-0.0473, -0.2301, -0.0649, -0.0621,  0.2681],\n",
      "          [-0.2652, -0.3424, -0.0857,  0.0417,  0.1529],\n",
      "          [-0.4303, -0.1406, -0.2261,  0.3896,  0.3756],\n",
      "          [-0.3348, -0.1118,  0.2039,  0.3735,  0.1749],\n",
      "          [ 0.0477,  0.0948,  0.0268,  0.2343,  0.2681]]]], requires_grad=True)\n",
      "conv1.bias torch.Size([6])\n",
      "Parameter containing:\n",
      "tensor([-0.0685,  0.0153,  0.0203,  0.0580, -0.0192, -0.1412],\n",
      "       requires_grad=True)\n",
      "conv2.weight torch.Size([16, 6, 5, 5])\n",
      "Parameter containing:\n",
      "tensor([[[[-8.9435e-02, -1.9128e-02, -7.2087e-02, -9.3911e-03,  1.9719e-02],\n",
      "          [ 1.3333e-01, -1.1610e-01, -2.9612e-02,  8.7279e-02,  4.3111e-02],\n",
      "          [ 1.9416e-01,  1.4152e-01, -1.8173e-02, -8.3838e-02,  5.8028e-03],\n",
      "          [ 2.4834e-01,  2.7544e-01, -1.1249e-01, -9.4678e-02,  8.5990e-02],\n",
      "          [-1.6954e-01, -3.8346e-02, -5.4788e-03, -1.7399e-02, -1.3478e-01]],\n",
      "\n",
      "         [[ 8.8722e-03,  6.6275e-02, -1.1198e-02,  7.0726e-02,  1.9212e-02],\n",
      "          [ 3.6608e-02,  1.0925e-01,  9.7085e-04, -5.6434e-02,  3.0099e-02],\n",
      "          [-9.2171e-02, -1.2843e-03, -9.8091e-02, -9.2875e-02,  6.6879e-02],\n",
      "          [-3.2779e-02,  1.7255e-01,  2.3392e-01, -5.6378e-02, -1.8962e-02],\n",
      "          [-1.4752e-01,  7.3804e-03, -1.1289e-02, -1.6076e-02, -2.1988e-02]],\n",
      "\n",
      "         [[-5.4964e-03, -3.2849e-02,  9.8963e-02, -6.8725e-02, -4.5245e-02],\n",
      "          [-1.5053e-01, -9.1350e-02, -5.9411e-02, -1.1519e-01, -8.3234e-02],\n",
      "          [-1.7171e-01, -1.6134e-01, -1.3944e-01, -1.3506e-01, -7.8263e-02],\n",
      "          [ 4.9815e-02,  1.9200e-02, -7.4359e-02,  1.9860e-02, -9.5114e-02],\n",
      "          [ 2.9568e-01,  2.2181e-01,  1.6783e-01,  9.6234e-03, -3.4980e-02]],\n",
      "\n",
      "         [[-7.9532e-02,  1.4440e-02,  1.3134e-01,  1.5314e-01,  7.0961e-02],\n",
      "          [-1.8987e-02,  5.7850e-02,  6.1412e-03,  8.0388e-02,  7.5329e-02],\n",
      "          [-1.5532e-01, -1.2438e-01, -2.0917e-01,  4.7874e-02, -5.7518e-02],\n",
      "          [-2.2076e-01, -2.0842e-01, -7.3188e-02, -5.8685e-02,  1.6002e-01],\n",
      "          [-1.0453e-01, -1.3560e-01, -3.2817e-02,  9.4669e-04, -3.9406e-02]],\n",
      "\n",
      "         [[ 6.8841e-02,  3.6492e-02, -1.6834e-02, -3.9106e-02, -1.3207e-01],\n",
      "          [ 1.7031e-03,  2.0293e-02,  2.1116e-02,  1.5307e-02, -3.6611e-02],\n",
      "          [ 8.6769e-02,  1.4292e-01, -7.0923e-03,  1.5437e-01,  2.5253e-02],\n",
      "          [ 1.5759e-02,  1.1194e-01,  1.8736e-01,  7.9332e-02,  8.2918e-02],\n",
      "          [ 3.4274e-02, -1.0234e-02,  1.4069e-01,  4.8623e-02,  3.4304e-02]],\n",
      "\n",
      "         [[-1.7839e-03,  5.9996e-02,  9.6892e-02, -8.7166e-02, -1.3697e-01],\n",
      "          [ 1.3565e-01, -4.7528e-02, -5.4918e-02,  5.5846e-02, -6.7585e-02],\n",
      "          [ 8.9001e-03, -1.3478e-01,  7.2760e-02,  4.3131e-02, -5.9900e-02],\n",
      "          [-6.2208e-02, -8.3432e-02, -1.4144e-01,  7.2006e-02, -1.5503e-01],\n",
      "          [-1.3015e-01, -2.2883e-01, -2.5730e-01, -1.8300e-01, -2.2013e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7175e-02,  1.4646e-01,  7.6474e-03, -1.1711e-01, -7.4342e-02],\n",
      "          [-6.7066e-02,  1.9058e-01,  2.1239e-01, -8.6175e-02,  2.8694e-02],\n",
      "          [-1.5522e-01,  1.4899e-01,  2.0359e-01,  8.6223e-02, -6.5908e-02],\n",
      "          [-2.1165e-01,  1.0011e-01,  8.5449e-02, -8.1217e-02,  1.0960e-02],\n",
      "          [-1.1852e-01, -5.3013e-02, -4.7321e-03, -6.6106e-02, -3.9663e-02]],\n",
      "\n",
      "         [[-1.1765e-01,  3.1923e-02,  3.7676e-02, -4.8729e-02, -7.8680e-02],\n",
      "          [-1.7272e-01, -9.4110e-02, -8.0940e-02, -3.7694e-02, -1.3665e-02],\n",
      "          [-2.5602e-01, -1.2611e-01,  4.4900e-02,  1.9507e-01,  1.1983e-01],\n",
      "          [-1.7377e-01, -2.4306e-01, -9.3680e-02, -3.7142e-02,  2.7672e-03],\n",
      "          [-4.3340e-01, -3.4585e-01, -1.5008e-01, -4.0441e-02, -1.3966e-01]],\n",
      "\n",
      "         [[-3.4267e-01, -8.9899e-02,  5.8326e-02,  1.0266e-01,  3.6523e-02],\n",
      "          [-1.3403e-01, -1.2854e-01, -7.3526e-02, -1.1799e-01,  6.4934e-02],\n",
      "          [-1.0810e-01,  5.1701e-02, -4.9235e-02, -1.2344e-01,  2.3272e-02],\n",
      "          [-9.3004e-02,  1.8705e-01,  6.4625e-02,  5.4094e-02, -1.6917e-02],\n",
      "          [ 3.3341e-02,  2.0014e-02, -5.6766e-02, -6.1040e-02, -2.1926e-02]],\n",
      "\n",
      "         [[-1.4810e-01,  2.8795e-01,  1.6667e-01,  2.8546e-02,  2.7253e-02],\n",
      "          [-1.9524e-01,  1.7789e-01,  2.6302e-01,  8.1743e-02, -8.9551e-02],\n",
      "          [-3.1603e-01,  5.1452e-02,  5.2708e-02, -4.5535e-02, -2.4251e-01],\n",
      "          [-4.6657e-02, -9.4140e-03, -4.5831e-03, -3.1723e-02, -1.2593e-03],\n",
      "          [ 1.0394e-01,  2.8716e-02,  7.5643e-02,  1.0709e-01, -1.8262e-03]],\n",
      "\n",
      "         [[-1.4584e-01,  1.5437e-02,  1.0196e-01,  9.9325e-02,  8.6405e-02],\n",
      "          [-1.9662e-01, -1.0567e-01,  7.3193e-02, -1.0263e-01, -7.3017e-02],\n",
      "          [-2.2588e-02, -1.7544e-02,  1.4800e-01,  5.1756e-02, -6.9420e-02],\n",
      "          [ 3.2544e-02,  2.2310e-02,  3.6879e-02,  4.6362e-02, -9.3635e-02],\n",
      "          [-3.4205e-02, -1.9507e-02, -9.9312e-02, -8.7526e-02, -1.3110e-01]],\n",
      "\n",
      "         [[ 1.6544e-01,  1.4420e-01,  3.2627e-02, -2.7578e-01, -2.6296e-01],\n",
      "          [ 2.6341e-01,  7.1460e-02, -1.7786e-01, -3.0114e-01, -1.4962e-01],\n",
      "          [ 2.1666e-01,  2.1493e-01, -1.9409e-01, -2.2812e-01, -1.4726e-01],\n",
      "          [ 1.1714e-01,  6.1527e-02, -1.0040e-01, -2.6348e-01, -1.4118e-01],\n",
      "          [-8.3457e-02, -1.0421e-01,  3.5930e-03, -1.1003e-02, -6.2841e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.1287e-02,  8.2089e-02,  5.9837e-02, -1.1433e-02,  2.0159e-02],\n",
      "          [ 2.3140e-02,  1.2290e-01,  5.4896e-02,  8.2761e-02,  6.6341e-02],\n",
      "          [ 2.5520e-03, -7.2660e-02, -1.0231e-01,  1.0480e-01, -4.8249e-03],\n",
      "          [ 5.4646e-02,  3.8505e-02,  1.7527e-02,  1.5893e-02, -8.5107e-02],\n",
      "          [ 5.1058e-02,  7.6712e-02, -1.1279e-01, -3.0088e-03,  4.3872e-02]],\n",
      "\n",
      "         [[ 8.3045e-03, -3.5889e-02, -3.8283e-02,  4.4731e-02, -4.9954e-02],\n",
      "          [ 2.3513e-01,  3.5827e-01,  3.0482e-01,  2.8438e-01,  1.0703e-01],\n",
      "          [ 1.2260e-01,  6.9219e-02,  3.6804e-02, -3.2171e-02, -2.2575e-02],\n",
      "          [ 1.5567e-02,  2.8677e-02,  7.2720e-02,  1.4895e-01, -1.7230e-02],\n",
      "          [ 4.5089e-02,  1.4893e-02,  7.2974e-02,  1.8896e-02,  1.6822e-02]],\n",
      "\n",
      "         [[ 6.1974e-02,  3.3564e-02, -1.4958e-01, -2.4659e-01, -9.4587e-02],\n",
      "          [-1.3561e-01, -8.5112e-02, -1.2819e-01, -1.9849e-01, -1.6753e-01],\n",
      "          [ 2.8150e-01,  1.6453e-01,  1.9352e-01,  6.3178e-02, -3.6929e-02],\n",
      "          [-2.0044e-02, -7.8956e-02, -1.6323e-01, -4.4372e-02, -7.7209e-02],\n",
      "          [-4.9615e-02, -4.0515e-02,  8.2819e-02, -7.8303e-02, -4.7256e-02]],\n",
      "\n",
      "         [[-2.4918e-01, -8.2215e-02, -1.3222e-02, -2.9535e-01, -2.2015e-01],\n",
      "          [-4.1226e-01, -4.4910e-01, -3.3597e-01, -3.2233e-01, -2.4477e-01],\n",
      "          [ 2.0378e-02, -1.5851e-01, -1.7450e-01, -1.7986e-01, -1.2883e-01],\n",
      "          [-1.5678e-02, -8.5412e-02, -2.2141e-01, -1.2317e-01, -3.3040e-03],\n",
      "          [-1.1039e-01, -2.6173e-01, -4.9248e-03,  7.0720e-02,  6.8574e-02]],\n",
      "\n",
      "         [[ 2.6995e-02,  8.4959e-03, -1.6677e-01, -2.1515e-01, -1.1712e-01],\n",
      "          [ 1.4861e-01,  2.4650e-01,  1.2135e-01,  1.5774e-01,  3.3144e-02],\n",
      "          [ 5.6572e-02,  1.6476e-01,  1.7744e-01, -1.6365e-02,  1.2847e-02],\n",
      "          [ 2.5202e-02, -6.9489e-02, -6.6395e-02,  5.8679e-02, -4.0021e-03],\n",
      "          [ 5.7712e-02,  3.1875e-02,  4.2512e-02,  8.2064e-02,  4.0655e-02]],\n",
      "\n",
      "         [[-1.1246e-01, -1.4969e-01, -2.9264e-02,  1.1812e-02,  5.0067e-02],\n",
      "          [ 3.0473e-02,  8.9752e-02,  5.7436e-02,  5.2434e-02, -1.6069e-01],\n",
      "          [-5.1634e-02,  1.1231e-03, -2.2257e-02, -2.3719e-01, -2.1931e-01],\n",
      "          [-1.5552e-02, -1.6811e-01, -1.8146e-02,  5.5310e-02, -3.7155e-02],\n",
      "          [-2.4557e-02, -3.6224e-02,  4.0337e-02, -5.6247e-02, -1.3937e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8247e-02,  2.5995e-02,  7.8819e-02,  9.8917e-02, -5.8210e-02],\n",
      "          [-4.5103e-02, -3.4860e-02, -1.7304e-04,  1.6103e-01, -4.3892e-02],\n",
      "          [-5.5105e-02, -4.5843e-02,  4.1976e-02,  8.0603e-02, -7.1391e-02],\n",
      "          [ 2.2376e-01,  8.3446e-02,  5.8740e-05, -5.0511e-02,  3.3203e-02],\n",
      "          [ 1.5663e-01,  8.6247e-02, -4.2226e-02, -2.0691e-02, -4.9604e-02]],\n",
      "\n",
      "         [[ 4.3782e-03, -7.1910e-03, -2.6156e-02, -3.2899e-02,  1.2709e-02],\n",
      "          [ 1.6074e-01, -5.3233e-02, -7.5895e-02,  5.7426e-02,  4.7293e-02],\n",
      "          [ 5.3979e-02, -5.0594e-02, -1.2791e-01, -9.8308e-02, -1.2441e-01],\n",
      "          [ 3.1385e-01,  3.2003e-01,  2.2148e-01,  3.9680e-02,  6.6608e-02],\n",
      "          [ 2.8385e-01,  2.7848e-01,  1.4308e-01,  5.8141e-02,  7.2934e-02]],\n",
      "\n",
      "         [[-3.3557e-02,  1.3974e-01, -1.7695e-02,  3.1909e-02,  2.0423e-01],\n",
      "          [ 4.7448e-02, -2.3983e-02,  1.4507e-01, -8.1022e-03,  6.3016e-02],\n",
      "          [ 3.4758e-02,  1.4002e-01,  1.3404e-01, -6.0826e-03, -1.2459e-01],\n",
      "          [-1.4920e-01, -4.3189e-01, -3.1611e-01, -1.5244e-01, -2.5213e-01],\n",
      "          [ 1.4406e-01,  1.0676e-01,  1.6157e-01,  6.7215e-02,  6.1047e-02]],\n",
      "\n",
      "         [[-1.0554e-01, -7.4366e-03,  1.7459e-01,  1.3011e-01,  3.7610e-03],\n",
      "          [-6.5055e-03,  3.2724e-02, -4.8663e-02,  2.8022e-02,  5.4447e-02],\n",
      "          [-6.7098e-02, -2.2199e-01, -3.1549e-01, -6.5678e-02, -7.9665e-02],\n",
      "          [-3.6221e-01, -4.7938e-01, -2.6072e-01, -5.1976e-02, -1.5070e-01],\n",
      "          [-2.4935e-01, -1.6144e-01,  4.0061e-02, -7.0665e-02,  8.7345e-03]],\n",
      "\n",
      "         [[-1.0725e-01, -2.2575e-03, -9.0014e-03,  5.9384e-03,  1.5908e-01],\n",
      "          [-3.5826e-02, -1.0958e-01, -6.6017e-03,  4.2891e-02,  4.2241e-02],\n",
      "          [-8.3147e-02, -2.7910e-01, -3.0904e-01, -1.7216e-01, -1.3851e-01],\n",
      "          [ 7.6326e-02, -3.7003e-02, -7.5506e-02, -8.7459e-02, -9.5344e-03],\n",
      "          [ 2.3327e-01,  1.9935e-01,  1.3545e-01,  1.1368e-01,  1.3261e-01]],\n",
      "\n",
      "         [[ 1.3259e-01,  1.4528e-01,  8.7471e-02,  6.4887e-02,  4.4862e-02],\n",
      "          [-1.0398e-01, -8.2029e-02,  2.9567e-03, -1.8559e-01, -1.9550e-01],\n",
      "          [-3.4273e-01, -2.3336e-01, -2.3787e-02, -2.6331e-01, -1.7721e-01],\n",
      "          [-6.6511e-02,  4.2629e-02,  4.4819e-02,  1.7479e-02,  1.1384e-01],\n",
      "          [ 1.1262e-01, -8.4154e-02,  2.6849e-03, -4.1567e-02, -1.1515e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2711e-02,  1.2384e-01, -8.0628e-02, -2.7216e-02,  1.0054e-01],\n",
      "          [ 9.3481e-02,  3.7648e-02,  5.6533e-02, -5.1688e-03,  6.4125e-02],\n",
      "          [-1.4247e-01, -2.1256e-01,  5.8071e-02, -3.3461e-02, -3.0619e-03],\n",
      "          [ 7.0798e-02, -1.0789e-02, -2.9610e-01, -1.1310e-01,  8.1181e-03],\n",
      "          [ 1.0806e-01,  1.2650e-01,  5.1009e-02, -1.3673e-01, -1.1903e-01]],\n",
      "\n",
      "         [[-7.5493e-02, -1.0034e-01,  8.1292e-02,  1.3127e-01,  1.4428e-01],\n",
      "          [ 6.1305e-02,  1.9436e-01,  1.5478e-01,  2.0344e-01,  6.1822e-02],\n",
      "          [-1.0583e-02, -7.2646e-02, -9.8111e-02, -3.7541e-02, -2.5904e-02],\n",
      "          [ 1.7209e-01,  8.9735e-02, -1.0987e-01,  2.1681e-03, -8.3596e-02],\n",
      "          [ 1.4607e-01,  8.6582e-02,  4.5693e-02, -8.1582e-03, -1.3213e-01]],\n",
      "\n",
      "         [[ 1.1297e-01, -7.5783e-04, -2.4673e-02,  7.6934e-02, -6.3595e-02],\n",
      "          [-3.8841e-02, -8.5611e-02,  5.1573e-02,  1.6824e-01,  2.3193e-02],\n",
      "          [ 1.2333e-01,  1.5152e-01,  2.7957e-01,  1.0331e-01, -2.0795e-03],\n",
      "          [-1.9338e-02,  1.8267e-02, -1.1847e-01, -8.5360e-02,  2.7346e-02],\n",
      "          [ 1.3279e-01, -2.3649e-01, -2.4891e-01,  4.4177e-02,  1.0412e-01]],\n",
      "\n",
      "         [[ 2.0100e-01,  6.5745e-02,  5.1715e-02, -2.2316e-01, -2.3921e-01],\n",
      "          [ 2.2664e-03, -1.5825e-01, -2.6983e-01, -2.5441e-01, -2.1264e-01],\n",
      "          [-4.5940e-02, -4.0516e-02, -6.0457e-03, -1.2890e-01, -1.4482e-01],\n",
      "          [-1.6562e-01, -7.2027e-03, -1.1629e-01, -2.0754e-01,  3.9819e-02],\n",
      "          [-6.0802e-02,  1.0569e-01,  1.2426e-01,  1.6327e-02,  1.7382e-01]],\n",
      "\n",
      "         [[ 1.0831e-01,  1.2661e-02,  9.5440e-02,  2.2079e-01,  1.9202e-01],\n",
      "          [-1.2247e-01,  1.1165e-01,  2.1828e-01,  2.5187e-01,  6.9676e-02],\n",
      "          [-1.4651e-01,  1.2645e-02,  4.9637e-02, -3.8626e-04, -9.4461e-02],\n",
      "          [-2.8019e-02, -1.6747e-01, -1.8262e-01, -1.4467e-01, -3.0807e-04],\n",
      "          [ 8.0638e-03,  2.2118e-02, -5.8065e-02,  4.2697e-02,  3.1464e-03]],\n",
      "\n",
      "         [[-7.5990e-03,  2.3372e-02,  3.7414e-02,  7.9590e-03, -9.7303e-03],\n",
      "          [-3.3260e-02, -2.6186e-02,  4.2867e-03, -1.1063e-01, -8.4392e-02],\n",
      "          [-1.5600e-01, -2.2125e-01, -2.4497e-01, -1.3199e-01, -5.4662e-03],\n",
      "          [-1.6501e-02, -2.1369e-01, -1.2507e-01,  1.1211e-01,  1.1383e-01],\n",
      "          [ 5.0998e-02,  3.8066e-02, -2.4334e-02, -3.6646e-02, -2.9342e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1443e-03, -9.3397e-02,  5.9784e-02, -5.7711e-02, -5.0482e-02],\n",
      "          [ 1.0113e-01,  1.2673e-01,  4.2378e-02, -1.9598e-02, -2.7501e-02],\n",
      "          [ 2.0026e-01,  2.3518e-02,  8.3740e-02,  3.4713e-02, -1.5827e-01],\n",
      "          [ 2.1461e-02,  1.6650e-02, -2.5174e-01, -2.9136e-01, -1.5121e-01],\n",
      "          [-1.0476e-01,  7.4061e-02, -3.5041e-02, -1.1239e-01, -1.0886e-01]],\n",
      "\n",
      "         [[ 7.2437e-02, -8.5089e-02, -1.9802e-02, -1.4255e-02, -1.1913e-02],\n",
      "          [ 1.4386e-01, -7.6039e-02,  8.1765e-02, -1.9003e-02,  1.2679e-02],\n",
      "          [ 5.2904e-02,  1.7623e-01,  1.4373e-01,  1.1234e-01,  8.8420e-02],\n",
      "          [-1.1067e-01, -2.3909e-01, -7.3894e-02, -1.6136e-01, -1.0742e-01],\n",
      "          [ 1.0728e-01,  8.0788e-02,  2.0128e-01,  3.2147e-01,  9.4362e-02]],\n",
      "\n",
      "         [[-1.4791e-01, -2.0983e-01, -1.3412e-01, -1.8773e-01, -1.8822e-01],\n",
      "          [-2.0211e-01, -7.9254e-02,  1.3756e-02, -3.5883e-02,  4.5327e-03],\n",
      "          [ 4.8117e-03,  6.3371e-02, -3.2841e-02,  1.7881e-02,  7.1414e-02],\n",
      "          [ 2.3042e-01,  2.1551e-01,  3.2896e-01,  2.3803e-01, -4.2556e-02],\n",
      "          [-1.2790e-01, -9.0491e-02, -1.7660e-01, -2.3202e-01, -1.9430e-01]],\n",
      "\n",
      "         [[ 8.9090e-02,  8.7217e-02,  1.1390e-01,  5.2785e-02,  2.2911e-01],\n",
      "          [-2.0331e-02, -1.7417e-01,  1.5974e-02,  1.0578e-01,  1.9317e-01],\n",
      "          [-1.5637e-01,  1.7642e-01,  1.1868e-01,  2.0566e-01,  1.4183e-01],\n",
      "          [-1.2986e-01, -7.7302e-03,  2.8505e-02,  1.1228e-01, -1.3025e-03],\n",
      "          [-1.7600e-01, -2.4593e-01, -2.5494e-01, -2.6473e-01, -1.1946e-01]],\n",
      "\n",
      "         [[ 7.6249e-02,  1.0501e-02,  9.6499e-02,  3.7788e-02, -2.1179e-03],\n",
      "          [ 6.9398e-03, -9.8156e-03,  1.2449e-01,  1.4373e-01,  1.2215e-01],\n",
      "          [ 9.6661e-02,  1.7303e-01,  1.0428e-01,  2.6878e-01,  1.4907e-01],\n",
      "          [-1.5046e-01, -7.0571e-02,  3.8483e-02, -7.5467e-02, -1.7098e-01],\n",
      "          [-7.7371e-03, -1.3082e-01, -1.6064e-01, -5.6473e-02, -1.6168e-02]],\n",
      "\n",
      "         [[-6.3982e-03, -1.1377e-02, -5.0167e-02,  5.3625e-02, -1.1207e-01],\n",
      "          [-1.0294e-01,  1.3938e-02, -4.8889e-03,  1.2262e-01,  1.1362e-01],\n",
      "          [-1.2097e-01, -2.8593e-02,  3.5700e-02,  4.5873e-02, -1.5885e-01],\n",
      "          [-2.7948e-01, -3.1397e-01, -2.4961e-01, -3.0363e-01, -2.4729e-01],\n",
      "          [-1.5279e-01, -1.9743e-01, -2.1227e-01,  4.8363e-02, -1.2494e-01]]]],\n",
      "       requires_grad=True)\n",
      "conv2.bias torch.Size([16])\n",
      "Parameter containing:\n",
      "tensor([-0.0530, -0.0484, -0.0677,  0.1224,  0.0425,  0.0283,  0.1158,  0.1005,\n",
      "         0.0199, -0.0099, -0.1932, -0.0794, -0.1017, -0.0391, -0.0191,  0.1250],\n",
      "       requires_grad=True)\n",
      "fc1.weight torch.Size([120, 256])\n",
      "Parameter containing:\n",
      "tensor([[-0.0664,  0.0001, -0.0846,  ..., -0.0420, -0.0045, -0.0920],\n",
      "        [ 0.0492, -0.0270, -0.0961,  ...,  0.0596,  0.0695, -0.0243],\n",
      "        [ 0.0461, -0.0546,  0.0094,  ..., -0.0465, -0.0315,  0.0210],\n",
      "        ...,\n",
      "        [-0.0194, -0.0551, -0.0506,  ..., -0.0308, -0.0356, -0.0320],\n",
      "        [ 0.0590,  0.0043, -0.0691,  ..., -0.1126, -0.1132, -0.0419],\n",
      "        [-0.0088,  0.0251,  0.0032,  ...,  0.0094,  0.0147,  0.0357]],\n",
      "       requires_grad=True)\n",
      "fc1.bias torch.Size([120])\n",
      "Parameter containing:\n",
      "tensor([ 0.0263,  0.0303,  0.0010, -0.0006, -0.0106,  0.0029, -0.0512,  0.0694,\n",
      "        -0.0077,  0.0010, -0.0927,  0.0037,  0.0521,  0.0377, -0.0861,  0.0614,\n",
      "         0.0188, -0.0463,  0.0515,  0.0051, -0.0421,  0.0347, -0.0659, -0.0178,\n",
      "        -0.0122,  0.1096, -0.0488,  0.0649,  0.0322,  0.0280, -0.0588, -0.0375,\n",
      "         0.1106,  0.0927, -0.0174, -0.0051,  0.0573, -0.0790, -0.0149, -0.0791,\n",
      "        -0.0042, -0.0686, -0.0557, -0.0393,  0.0923, -0.0521, -0.0727, -0.0521,\n",
      "         0.0357, -0.0553,  0.0444, -0.0349, -0.0282, -0.0543, -0.0289, -0.0041,\n",
      "         0.0063,  0.0467, -0.0689,  0.0030,  0.0175, -0.0907, -0.0072, -0.0078,\n",
      "         0.0473, -0.0436, -0.0717, -0.0780, -0.0653,  0.0250, -0.0366,  0.0577,\n",
      "         0.1157,  0.1491, -0.0170, -0.0076,  0.0370, -0.1020, -0.0404,  0.0803,\n",
      "        -0.0526,  0.0116, -0.0616, -0.0044, -0.0194,  0.1234, -0.0203,  0.0732,\n",
      "         0.0319,  0.0450, -0.0303, -0.0446,  0.0277,  0.0786,  0.0277, -0.0459,\n",
      "        -0.0497,  0.0783, -0.0207, -0.0245, -0.0185,  0.0229,  0.0445, -0.0036,\n",
      "         0.0246,  0.1039, -0.0600,  0.0448, -0.0552, -0.0447, -0.0787,  0.0064,\n",
      "        -0.0381, -0.0222,  0.0359, -0.0057,  0.1118,  0.0048, -0.0238, -0.0610],\n",
      "       requires_grad=True)\n",
      "fc2.weight torch.Size([84, 120])\n",
      "Parameter containing:\n",
      "tensor([[-0.1003,  0.0691,  0.0101,  ...,  0.0762, -0.0805, -0.0700],\n",
      "        [ 0.0318,  0.1367, -0.0411,  ..., -0.0286, -0.1380, -0.0149],\n",
      "        [ 0.0178, -0.0642, -0.0027,  ..., -0.0805, -0.2072,  0.0566],\n",
      "        ...,\n",
      "        [ 0.0169, -0.0762, -0.0015,  ..., -0.0583,  0.1052, -0.1240],\n",
      "        [ 0.0225,  0.1613,  0.0247,  ..., -0.0744, -0.0297, -0.0980],\n",
      "        [ 0.0801, -0.0943,  0.0243,  ...,  0.0394, -0.0472, -0.0132]],\n",
      "       requires_grad=True)\n",
      "fc2.bias torch.Size([84])\n",
      "Parameter containing:\n",
      "tensor([ 0.1162,  0.1806, -0.0320,  0.0917,  0.0486, -0.0364, -0.0869, -0.0134,\n",
      "         0.1688,  0.0067,  0.0329,  0.0737,  0.0203, -0.0669, -0.0136, -0.0415,\n",
      "         0.0188, -0.0126,  0.0676,  0.1102,  0.0796,  0.1369, -0.0297,  0.1933,\n",
      "         0.0350, -0.0342, -0.0026,  0.0799,  0.1073, -0.1136,  0.0625,  0.0703,\n",
      "         0.1355, -0.0923,  0.0458, -0.0141, -0.1141, -0.0846,  0.0276, -0.0226,\n",
      "         0.0561,  0.0669, -0.0732,  0.0202, -0.0732, -0.0082,  0.0370,  0.1427,\n",
      "        -0.0051,  0.0455,  0.1343, -0.0004, -0.0915,  0.0138,  0.0220, -0.0867,\n",
      "         0.0644,  0.0293, -0.1152, -0.1168,  0.1014, -0.0576, -0.0947,  0.0347,\n",
      "         0.1447,  0.0467, -0.0187,  0.0432,  0.0897,  0.0090,  0.1096,  0.0765,\n",
      "        -0.0927, -0.1198,  0.0616,  0.0500, -0.1472,  0.0246,  0.0068,  0.0837,\n",
      "         0.0003,  0.0843, -0.1028, -0.0870], requires_grad=True)\n",
      "fc3.weight torch.Size([10, 84])\n",
      "Parameter containing:\n",
      "tensor([[-1.1075e-01, -3.0714e-01, -1.5907e-02, -7.0541e-02, -2.1941e-01,\n",
      "         -3.2538e-01,  1.8899e-01,  1.4345e-01, -7.4459e-02, -1.4170e-01,\n",
      "          4.2213e-02,  7.8088e-02, -1.4080e-01,  1.0251e-02, -1.3275e-01,\n",
      "         -3.5912e-03,  1.5807e-01, -1.4655e-01, -2.8488e-01, -1.5441e-01,\n",
      "         -8.3135e-03,  1.2091e-01,  1.2003e-01,  1.5822e-01,  7.0403e-02,\n",
      "          5.8595e-02,  2.4891e-01, -1.7001e-02, -1.6831e-01, -1.2770e-01,\n",
      "          1.5150e-02,  5.8917e-02, -2.7839e-01, -1.7988e-01,  1.1458e-01,\n",
      "          2.6962e-01, -1.4471e-01, -5.0641e-02, -1.3590e-01,  6.4337e-02,\n",
      "         -2.6517e-01, -5.7161e-02, -1.0530e-01,  7.7029e-02,  5.7630e-03,\n",
      "         -9.3082e-02, -1.1982e-01,  8.7105e-03, -9.0551e-02, -2.1315e-01,\n",
      "          6.8306e-02,  1.1802e-01,  3.3225e-02,  4.1685e-02, -1.2252e-01,\n",
      "         -9.2957e-02,  6.9966e-02,  1.0915e-01, -2.4171e-01, -1.1346e-01,\n",
      "         -1.0571e-01, -7.8311e-02, -1.1944e-01, -6.5614e-02,  6.3368e-02,\n",
      "         -2.8834e-01, -2.4576e-01, -1.7418e-01, -4.0867e-01,  1.8864e-01,\n",
      "          8.0156e-02, -2.5451e-01, -6.8886e-03,  4.3947e-02,  1.2396e-01,\n",
      "          3.4173e-02, -5.3393e-02,  1.5774e-01, -7.6506e-02,  2.2243e-01,\n",
      "          2.2531e-02,  1.4369e-01, -3.3455e-01,  1.1317e-02],\n",
      "        [ 5.3496e-02, -1.2172e-02, -2.0279e-01, -2.1626e-01,  3.2259e-02,\n",
      "         -2.1803e-01,  1.3344e-01,  1.9541e-01, -2.1729e-01,  1.5776e-01,\n",
      "         -1.1311e-01,  1.4164e-01,  1.9996e-02, -1.1137e-01, -2.5445e-01,\n",
      "         -2.3285e-01, -5.4031e-02,  1.4582e-01, -1.3503e-01, -7.5666e-02,\n",
      "         -4.2348e-02, -1.5474e-01,  1.1968e-01, -3.6646e-02, -8.5095e-02,\n",
      "         -1.8806e-01,  2.2295e-02, -1.4886e-01,  1.0220e-01, -4.3669e-02,\n",
      "         -1.6924e-01,  1.1072e-01, -2.5011e-02,  1.4464e-01, -3.2446e-01,\n",
      "         -1.5850e-01,  1.7619e-01,  1.7687e-01, -1.6074e-01, -1.1936e-01,\n",
      "          1.3283e-01, -5.9632e-02, -3.5879e-01,  3.8994e-02, -1.3287e-01,\n",
      "         -1.5629e-01, -2.4940e-01, -1.6647e-01, -1.2252e-01, -2.6558e-02,\n",
      "         -1.2996e-01,  4.8412e-02, -7.9561e-02, -3.2770e-01,  2.4942e-01,\n",
      "          5.4125e-02, -1.1808e-01,  1.6818e-01,  1.5084e-01, -1.7936e-01,\n",
      "         -1.1591e-01, -1.0033e-01,  1.1101e-01,  6.2635e-02,  7.4759e-02,\n",
      "          1.8658e-01,  1.2531e-02,  1.2398e-02, -2.1491e-01, -2.4648e-01,\n",
      "         -2.9463e-02,  1.4612e-01, -6.1342e-03,  2.8452e-02,  1.3363e-01,\n",
      "          2.6788e-02, -2.9209e-02,  1.4217e-01, -2.4726e-01, -2.2963e-01,\n",
      "         -1.8652e-01, -3.5791e-02,  5.2753e-02, -1.0549e-01],\n",
      "        [ 1.7241e-01, -1.5651e-01, -1.5492e-01,  1.1165e-01, -1.6870e-01,\n",
      "          1.8641e-02, -3.6618e-02, -1.3151e-01, -5.4969e-02, -1.4619e-01,\n",
      "         -1.0596e-01, -1.1080e-01, -1.5798e-01,  2.0372e-01,  1.0416e-01,\n",
      "         -1.6334e-01, -1.7644e-01,  1.6807e-02,  1.1251e-01,  4.8121e-02,\n",
      "         -7.2265e-03,  1.4136e-01,  8.0752e-02, -2.5847e-01,  4.4279e-02,\n",
      "         -5.1145e-02, -1.5285e-01,  8.4885e-02, -1.0018e-01, -3.0545e-01,\n",
      "         -2.4290e-01, -1.6881e-02, -2.1017e-01, -1.3090e-01, -1.1372e-01,\n",
      "          1.7939e-01,  6.1056e-02,  4.0741e-02, -1.3070e-01,  8.3014e-02,\n",
      "         -3.1145e-02, -1.6694e-01,  5.1949e-02,  1.3354e-01,  2.2429e-02,\n",
      "         -5.7838e-02,  1.8990e-01,  3.3800e-03, -4.2388e-02,  6.1545e-02,\n",
      "          1.9078e-03,  1.8012e-01,  2.6194e-02, -6.2776e-03, -6.2616e-02,\n",
      "         -3.6745e-02,  1.2644e-01,  6.2306e-02, -4.4540e-02, -1.3474e-01,\n",
      "          1.0688e-02,  5.6815e-02, -3.1750e-02, -2.6940e-01, -1.2413e-01,\n",
      "          1.7625e-01,  1.3550e-01, -8.8205e-02, -2.5815e-01, -2.0627e-02,\n",
      "         -2.7541e-01,  6.9025e-02,  1.1443e-02,  1.3743e-01, -3.5791e-01,\n",
      "         -1.2292e-01, -1.1913e-01, -2.0727e-02,  1.5558e-01,  6.9242e-02,\n",
      "         -1.0357e-01,  8.7897e-02, -7.3124e-02, -3.6731e-02],\n",
      "        [-1.7725e-01, -4.6377e-02,  1.3768e-01, -9.5566e-03,  1.0365e-01,\n",
      "         -2.6854e-02, -1.3515e-01, -2.2008e-01, -6.8752e-02, -4.5886e-02,\n",
      "         -7.7320e-02, -1.1625e-01, -1.1547e-01,  1.4204e-02, -6.8802e-02,\n",
      "         -2.4188e-01,  1.0045e-01,  8.6392e-02,  1.0209e-01,  2.0427e-01,\n",
      "          9.1973e-02, -9.8734e-02,  8.8802e-02, -2.0162e-01, -1.8049e-01,\n",
      "         -7.9648e-02, -2.2130e-01,  1.9887e-01,  1.2792e-01, -2.0973e-01,\n",
      "         -7.8271e-02,  2.0030e-01, -4.6862e-02, -1.6693e-01,  3.1387e-02,\n",
      "         -1.8912e-01, -1.4137e-02, -2.3051e-01, -9.7272e-02, -8.6703e-02,\n",
      "         -1.0899e-01, -1.5379e-01,  1.0441e-01, -6.7743e-02,  2.7479e-02,\n",
      "          2.1996e-01, -1.2606e-01,  1.1112e-01,  1.3858e-01, -3.3401e-02,\n",
      "         -6.1681e-02,  4.4084e-02, -4.0278e-02,  1.2685e-01, -1.0682e-01,\n",
      "         -3.9173e-01, -5.2394e-04, -1.4331e-01, -4.3574e-02,  2.4205e-02,\n",
      "         -1.7258e-01,  4.9279e-02, -1.7011e-01, -2.0061e-01, -4.5994e-02,\n",
      "         -1.1380e-01,  1.2249e-01,  8.7193e-02, -2.4790e-01,  5.3253e-02,\n",
      "          5.2582e-02,  4.4718e-02, -6.9832e-02,  1.3492e-01, -1.6676e-01,\n",
      "          1.7504e-01, -9.6877e-02, -2.8140e-01, -2.1000e-01, -1.5886e-01,\n",
      "          1.0615e-01, -3.0763e-02, -1.7383e-01, -1.2538e-01],\n",
      "        [ 5.6105e-02,  1.4672e-01,  1.4902e-01,  1.5097e-01,  6.8629e-02,\n",
      "          9.1091e-02,  1.6544e-02,  4.0434e-03, -4.2382e-03,  2.3477e-02,\n",
      "         -1.0985e-01, -2.0235e-01, -9.5034e-02, -4.0602e-02,  1.9002e-01,\n",
      "         -1.7493e-01, -2.1602e-01,  1.0789e-02, -2.5623e-01, -1.9183e-01,\n",
      "         -8.9774e-02,  7.2864e-02, -3.3192e-01,  8.5959e-02,  1.9189e-01,\n",
      "          1.0881e-01, -1.9174e-02,  3.2085e-03, -2.0368e-01, -1.4643e-01,\n",
      "          1.4733e-01,  1.7853e-01, -3.0571e-02, -5.7574e-02,  9.2609e-03,\n",
      "         -2.0858e-01, -4.4866e-02, -9.7616e-03, -2.8368e-01, -1.4718e-01,\n",
      "          2.0579e-02,  3.7630e-02,  1.2803e-01,  1.3343e-01, -1.2682e-01,\n",
      "         -1.2624e-01,  1.5162e-01, -3.1754e-01,  1.0970e-01, -7.9935e-02,\n",
      "         -4.8292e-02, -3.4026e-02, -5.4199e-02,  5.5026e-03, -1.4783e-01,\n",
      "         -1.6642e-01, -1.7499e-01, -2.4399e-02,  7.3540e-02,  3.0408e-03,\n",
      "          8.5126e-02,  9.4670e-02,  6.7783e-02,  5.3120e-02, -3.2978e-01,\n",
      "         -1.6420e-02,  1.4490e-02,  7.8611e-02,  2.0368e-01, -1.0882e-01,\n",
      "         -1.8813e-01, -3.1144e-02, -9.2924e-02, -1.4285e-01,  6.4566e-02,\n",
      "         -2.5409e-01, -3.6605e-02, -6.0971e-02, -3.4209e-02,  4.5193e-02,\n",
      "         -2.2704e-01, -2.0198e-01,  6.4990e-02, -1.7784e-01],\n",
      "        [-1.3657e-01,  4.0078e-02, -1.0087e-01, -1.9743e-01,  1.1036e-01,\n",
      "          3.3207e-02, -8.5521e-02, -4.9303e-02, -1.7132e-01,  3.6251e-02,\n",
      "         -8.5829e-02,  1.5361e-02,  9.8261e-02, -6.6384e-03,  1.2603e-01,\n",
      "         -1.1409e-01,  4.1285e-02, -1.0267e-01,  7.9530e-02,  7.8777e-02,\n",
      "         -7.6184e-02, -2.6431e-02, -1.6559e-01, -2.1360e-01, -1.0973e-01,\n",
      "          1.3954e-02,  2.4050e-02, -1.5234e-01, -4.0181e-02, -4.2161e-01,\n",
      "          1.4009e-02, -1.8324e-01,  2.4183e-02, -7.1688e-03,  1.5667e-01,\n",
      "         -8.0782e-02,  2.0583e-01,  3.5677e-02,  1.1449e-01,  6.3968e-02,\n",
      "         -1.5096e-02,  1.3236e-01, -1.6611e-01, -1.9555e-01,  1.6919e-02,\n",
      "          3.2679e-02, -1.1741e-01,  3.3179e-02,  1.4526e-01, -6.2629e-02,\n",
      "         -8.9831e-03, -3.0793e-02, -4.6751e-02,  1.2621e-01, -4.8842e-02,\n",
      "         -6.5277e-02,  7.1059e-02, -1.2841e-01,  1.0059e-01, -7.3369e-02,\n",
      "          1.3170e-01,  3.0023e-02, -3.2904e-01,  9.7207e-02, -2.5108e-02,\n",
      "         -2.3582e-01, -2.3511e-01, -1.0866e-01, -1.2327e-01,  1.7504e-01,\n",
      "          1.1398e-01, -3.3736e-02,  8.7179e-03,  7.9699e-02, -1.1591e-02,\n",
      "          1.1511e-02, -1.0184e-02, -8.2921e-02, -1.3493e-01, -2.6770e-01,\n",
      "          8.7286e-04,  7.3263e-02, -2.9000e-01,  4.7504e-02],\n",
      "        [-4.3616e-03, -2.5845e-02,  5.6484e-02,  1.1167e-01, -3.2308e-01,\n",
      "         -3.3318e-01,  1.5875e-01,  1.8773e-01, -2.5950e-01, -2.3831e-01,\n",
      "          6.7865e-02, -1.2387e-01,  1.5813e-01,  1.4051e-01,  1.1578e-01,\n",
      "          3.9336e-02, -4.2349e-02,  8.6756e-02, -7.6229e-02,  6.8320e-02,\n",
      "         -1.7173e-01, -1.0861e-01, -2.2307e-01,  1.5297e-03, -2.5265e-01,\n",
      "         -1.6077e-01,  2.9119e-02, -3.0816e-01, -2.2244e-01, -3.5252e-01,\n",
      "          1.4503e-01,  1.7351e-01,  5.1521e-02, -9.6249e-02,  1.1482e-01,\n",
      "          3.4469e-02, -6.4018e-02, -3.1734e-03,  1.0094e-01,  1.5521e-01,\n",
      "         -1.3730e-01, -2.0626e-02,  1.4444e-01,  3.9044e-02, -1.2166e-01,\n",
      "          1.0308e-01, -2.9425e-01, -1.3682e-02, -1.8626e-01, -4.2082e-01,\n",
      "         -7.9620e-03, -1.8902e-01, -6.5302e-02,  7.4368e-02, -4.0645e-02,\n",
      "          1.1435e-02, -9.2212e-02,  1.2087e-01, -1.4898e-01,  8.1577e-02,\n",
      "          1.5027e-01,  1.8531e-02, -5.2364e-02,  1.6899e-01, -6.7443e-02,\n",
      "          9.2640e-05, -3.0551e-01, -1.5295e-01, -1.3106e-01,  1.4011e-02,\n",
      "          1.7903e-01,  5.7190e-03, -1.9211e-02, -6.4886e-02, -1.0328e-01,\n",
      "         -2.8584e-01,  4.5274e-02,  4.0614e-02, -2.1581e-01, -3.8442e-03,\n",
      "         -2.7889e-01, -3.5819e-02, -3.8441e-01,  1.1240e-03],\n",
      "        [-1.2642e-01, -3.6938e-02, -1.6404e-01,  1.4240e-01,  1.3066e-01,\n",
      "          1.1929e-01,  1.0056e-01, -8.1407e-02,  1.5337e-01, -3.4051e-02,\n",
      "          6.8479e-02,  1.1461e-01, -2.0798e-01, -2.6384e-01, -1.5080e-01,\n",
      "         -3.7904e-01,  1.3178e-01,  1.4397e-01, -7.9919e-02, -2.0436e-02,\n",
      "          1.6974e-01, -2.8969e-02, -8.1317e-02, -1.3581e-01,  1.6286e-02,\n",
      "          3.4386e-02, -2.8269e-02, -5.2059e-02, -1.0732e-01, -2.6131e-03,\n",
      "          8.0163e-02,  7.6484e-03, -2.7803e-01,  1.2160e-01,  6.4977e-02,\n",
      "         -2.1745e-02, -5.9348e-02, -1.4008e-01, -9.2859e-02, -2.7966e-01,\n",
      "          1.5267e-01,  6.1120e-02,  2.5550e-01, -1.5381e-01, -2.3299e-02,\n",
      "         -1.4691e-01, -4.8003e-02, -1.5405e-01, -2.9258e-01,  2.0038e-01,\n",
      "         -4.5758e-02,  1.8122e-02,  6.8666e-02, -7.7556e-02,  2.3786e-01,\n",
      "         -4.8881e-02, -3.4975e-02, -1.0295e-01,  7.4839e-02, -1.4604e-02,\n",
      "         -2.9295e-01,  5.1219e-02,  8.2521e-03, -1.3831e-01, -1.9816e-01,\n",
      "          2.0213e-01,  5.0953e-02,  7.4260e-02,  8.2429e-02,  1.7627e-01,\n",
      "         -3.5988e-01, -2.0958e-02,  2.2032e-02,  9.2943e-02, -9.6921e-03,\n",
      "          5.7165e-02, -5.5844e-02, -3.0084e-02,  1.2824e-01, -2.4146e-01,\n",
      "          1.4200e-02,  5.6289e-02,  1.1056e-01,  3.4664e-03],\n",
      "        [ 2.0545e-01,  9.2816e-02, -1.9653e-02, -8.0618e-02, -8.0895e-02,\n",
      "         -1.2873e-01, -2.1359e-02, -1.1236e-01,  1.4203e-01, -9.4647e-02,\n",
      "          3.8013e-03,  1.1996e-01,  7.2150e-02, -2.5303e-01, -1.0984e-01,\n",
      "         -1.6446e-01, -2.5828e-02,  4.8914e-02,  1.3614e-01,  7.5985e-02,\n",
      "          4.6264e-02,  1.5064e-01,  3.0002e-03,  1.5631e-01, -6.7404e-03,\n",
      "         -1.3846e-01,  2.0354e-02,  8.9572e-02,  1.1709e-01, -4.3811e-01,\n",
      "         -1.4467e-01, -1.1895e-01,  7.1941e-02, -2.5575e-01, -9.1754e-02,\n",
      "         -9.6906e-02, -1.1185e-01, -5.6467e-02,  1.6611e-01, -3.3620e-03,\n",
      "         -1.7105e-02,  1.3304e-01, -1.1819e-01,  1.0018e-01, -3.2649e-03,\n",
      "         -2.0324e-01,  4.0167e-02,  1.0381e-01, -1.5138e-02, -3.8262e-03,\n",
      "          6.3798e-02, -2.8225e-01, -3.5307e-02, -5.5500e-02, -1.9749e-01,\n",
      "          7.9196e-02, -1.1473e-02, -2.1389e-01, -3.6045e-01, -6.7707e-02,\n",
      "          7.7132e-02,  1.0631e-02, -2.9859e-01, -1.0263e-02,  2.0096e-01,\n",
      "         -7.1483e-02,  6.0438e-02,  1.2839e-01,  9.6881e-03, -2.3718e-01,\n",
      "          3.9961e-02,  8.7176e-03, -1.1473e-01, -2.2269e-01,  4.8786e-02,\n",
      "         -1.7436e-01, -1.6875e-01, -1.9566e-02, -1.3076e-01, -1.1621e-01,\n",
      "         -1.5796e-01,  8.4269e-02, -2.1410e-01,  4.1018e-02],\n",
      "        [-1.3214e-01,  3.3070e-03, -7.5688e-02,  2.9566e-02,  7.5258e-02,\n",
      "          1.3912e-01, -1.4234e-01, -8.9839e-02,  6.5372e-02,  1.6084e-02,\n",
      "         -3.1775e-02,  1.4792e-01, -3.9295e-02,  5.3755e-02, -4.5567e-03,\n",
      "         -1.3804e-01,  2.6864e-02, -3.4131e-01, -3.0207e-01, -2.4960e-01,\n",
      "         -3.9020e-02, -2.2124e-01,  1.7323e-02,  8.0868e-02,  9.1782e-02,\n",
      "          1.9853e-01, -2.4106e-01,  1.0337e-01, -1.2897e-01, -5.5849e-02,\n",
      "          1.3030e-01, -2.9810e-01,  1.1386e-01, -2.2275e-01,  1.6253e-02,\n",
      "          1.4437e-01, -2.3497e-01, -3.5954e-01, -1.4960e-01,  1.0968e-02,\n",
      "         -4.9615e-02, -1.0954e-01, -3.1305e-01,  3.6159e-02, -1.5230e-02,\n",
      "          8.3226e-02,  1.3083e-01,  2.3661e-02,  2.6577e-03, -7.3925e-03,\n",
      "         -1.9061e-01, -1.3151e-01,  8.4528e-02, -2.7917e-02, -1.4558e-01,\n",
      "         -4.8502e-01,  1.2766e-01,  7.0356e-02,  1.2850e-01, -1.7862e-01,\n",
      "          1.2499e-01, -1.1802e-02,  2.0785e-01,  1.1881e-01, -1.4722e-01,\n",
      "         -1.0646e-01,  2.2203e-02,  8.4635e-02,  1.5208e-01, -1.0425e-01,\n",
      "          4.7275e-02,  1.3984e-01, -2.4243e-02, -1.1520e-02, -8.1748e-03,\n",
      "          1.1469e-01,  1.5408e-02, -2.6004e-01, -2.1961e-02,  7.3806e-02,\n",
      "          1.2950e-01, -1.8960e-01, -2.6018e-02, -2.1769e-03]],\n",
      "       requires_grad=True)\n",
      "fc3.bias torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([-0.1480, -0.1316,  0.0920, -0.0718,  0.0426,  0.0561, -0.1572,  0.0331,\n",
      "         0.0918, -0.0123], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
