{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "---\n",
      "conv1.0.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.0.bias torch.Size([6])\n",
      "conv2.0.weight torch.Size([16, 6, 5, 5])\n",
      "conv2.0.bias torch.Size([16])\n",
      "fc1.0.weight torch.Size([120, 256])\n",
      "fc1.0.bias torch.Size([120])\n",
      "fc2.0.weight torch.Size([84, 120])\n",
      "fc2.0.bias torch.Size([84])\n",
      "fc3.weight torch.Size([10, 84])\n",
      "fc3.bias torch.Size([10])\n",
      "total parameters: 44426\n",
      "input x to model: torch.Size([64, 1, 28, 28])\n",
      "conv1 after size: torch.Size([64, 6, 12, 12])\n",
      "conv2 after size: torch.Size([64, 16, 4, 4])\n",
      "fc1 after size: torch.Size([64, 120])\n",
      "fc2 after size: torch.Size([64, 84])\n",
      "fc3 after size: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 1, 28, 28)\n",
    "        conv1: (1, 28, 28) -> (6, 24, 24) -> (6, 12, 12)\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 6, 12, 12)\n",
    "        conv2: (6, 12, 12) -> (16, 8, 8) -> (16, 4, 4)\n",
    "        \"\"\"\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 16, 4, 4)\n",
    "        fc1: (16, 4, 4) -> (120,)\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 120),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 120)\n",
    "        fc2: (120,) -> (84,)\n",
    "        \"\"\"\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 84)\n",
    "        fc3: (84,) -> (10,)\n",
    "        \"\"\"\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 1, 28, 28)\n",
    "        \"\"\"\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 1, 28, 28)\n",
    "        conv1: (1, 28, 28) -> (6, 24, 24) -> (6, 12, 12)\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 6, 12, 12)\n",
    "        conv2: (6, 12, 12) -> (16, 8, 8) -> (16, 4, 4)\n",
    "        \"\"\"\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        \"\"\"\n",
    "        flatten\n",
    "        input shape: (batch_size, 16, 4, 4)\n",
    "        output shape: (batch_size, 16*4*4)\n",
    "        \"\"\"\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 16*4*4)\n",
    "        fc1: (16*4*4) -> (120,)\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 120)\n",
    "        fc2: (120,) -> (84,)\n",
    "        \"\"\"\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, 84)\n",
    "        fc3: (84,) -> (10,)\n",
    "        \"\"\"\n",
    "        output = self.fc3(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            prob_list = prob.squeeze().tolist()\n",
    "            prob, index = torch.max(prob, 1)\n",
    "        return index, prob, prob_list\n",
    "\n",
    "\n",
    "def print_params(model):\n",
    "    count = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        count += param.numel()\n",
    "        print(name, param.shape)\n",
    "    print('total parameters:', count)\n",
    "\n",
    "\n",
    "def print_forward(model, x):\n",
    "    print('input x to model:', x.shape)\n",
    "    for name, layer in model.named_children():\n",
    "        if name == 'fc1':\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        x = layer(x)\n",
    "        print(f'{name} after size: {x.shape}')\n",
    "\n",
    "\n",
    "test_model = LeNet()\n",
    "print(test_model)\n",
    "print('---')\n",
    "print_params(test_model)\n",
    "\n",
    "x = torch.randn(64, 1, 28, 28)\n",
    "print_forward(test_model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 设置全局随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(seed + worker_id)\n",
    "    random.seed(seed + worker_id)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(12),  # 随机旋转 12 度\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载训练数据集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# 定义训练数据加载器\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=64, shuffle=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwuhonglei1017368065\u001b[0m (\u001b[33mwuhonglei1017368065-shopee\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/honglei.wu/Desktop/机器学习/code/dh_ai/week10-卷积神经网络/wandb/run-20240905_104945-y3yyr0cf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/y3yyr0cf' target=\"_blank\">crimson-resonance-44</a></strong> to <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/y3yyr0cf' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/y3yyr0cf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/938], Loss: 0.6048\n",
      "Epoch [1/2], Step [200/938], Loss: 0.4315\n",
      "Epoch [1/2], Step [300/938], Loss: 0.2499\n",
      "Epoch [1/2], Step [400/938], Loss: 0.2733\n",
      "Epoch [1/2], Step [500/938], Loss: 0.1536\n",
      "Epoch [1/2], Step [600/938], Loss: 0.1178\n",
      "Epoch [1/2], Step [700/938], Loss: 0.2824\n",
      "Epoch [1/2], Step [800/938], Loss: 0.0920\n",
      "Epoch [1/2], Step [900/938], Loss: 0.1412\n",
      "Epoch [2/2], Step [100/938], Loss: 0.0849\n",
      "Epoch [2/2], Step [200/938], Loss: 0.0586\n",
      "Epoch [2/2], Step [300/938], Loss: 0.1368\n",
      "Epoch [2/2], Step [400/938], Loss: 0.2526\n",
      "Epoch [2/2], Step [500/938], Loss: 0.0564\n",
      "Epoch [2/2], Step [600/938], Loss: 0.1056\n",
      "Epoch [2/2], Step [700/938], Loss: 0.1014\n",
      "Epoch [2/2], Step [800/938], Loss: 0.0392\n",
      "Epoch [2/2], Step [900/938], Loss: 0.0252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁█</td></tr><tr><td>test_loss</td><td>█▁</td></tr><tr><td>train_accuracy</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9793</td></tr><tr><td>test_loss</td><td>0.06109</td></tr><tr><td>train_accuracy</td><td>0.9677</td></tr><tr><td>train_loss</td><td>0.10369</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-resonance-44</strong> at: <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/y3yyr0cf' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/runs/y3yyr0cf</a><br/> View project at: <a href='https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB' target=\"_blank\">https://wandb.ai/wuhonglei1017368065-shopee/MNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240905_104945-y3yyr0cf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.require(\"core\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def calculate_test_performance(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() * len(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "epochs = 2\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "total = len(train_loader.dataset)  # type: ignore\n",
    "\n",
    "wandb_init_args = {\n",
    "    'project': 'MNIST-手写数字识别',\n",
    "    'config': {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": \"LeNet-5\",\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    "    'reinit': True\n",
    "}\n",
    "run = wandb.init(**wandb_init_args, job_type=\"training\")\n",
    "wandb_init_args['name'] = run.name\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    test_loss, test_accuracy = calculate_test_performance(\n",
    "        model, test_loader, criterion)\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss / total,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"train_accuracy\": train_correct / total,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/14nkpqsn4zs8c1dmkl0p4mxr0000gp/T/ipykernel_65232/703398484.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet()\n",
    "model.load_state_dict(torch.load(\n",
    "    './model.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2, 1: 4, 2: 4, 3: 9, 4: 13, 5: 10, 6: 12, 7: 15, 8: 6, 9: 12}\n",
      "error-count: 87\n",
      "Accuracy of the network on the 10000 test images: 99.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 测试模型\n",
    "model.eval()  # 切换到评估模式\n",
    "with torch.no_grad():\n",
    "    \"\"\" 统计每个数字的错误次数 \"\"\"\n",
    "    error_count_dict = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 0,\n",
    "        5: 0,\n",
    "        6: 0,\n",
    "        7: 0,\n",
    "        8: 0,\n",
    "        9: 0\n",
    "    }\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_index, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error_index = np.where((predicted == labels).cpu().numpy() == False)[0]\n",
    "        for index in error_index:\n",
    "            error_count_dict[labels[index].item()] += 1\n",
    "\n",
    "test_loss /= total\n",
    "test_accuracy = correct / total\n",
    "\n",
    "pprint(error_count_dict)\n",
    "print('error-count:', sum(error_count_dict.values()))\n",
    "print('Accuracy of the network on the 10000 test images: {:.2f}%'.format(\n",
    "    100 * test_accuracy))\n",
    "\n",
    "# 将每个数字的错误次数绘制为柱状图\n",
    "plt.bar(error_count_dict.keys(), error_count_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存后加载模型\n",
    "torch.save(model.state_dict(), './model.pth')\n",
    "\n",
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('./server/model.pth'))\n",
    "\n",
    "# # 创建一个示例输入张量（假设输入尺寸是 [1, 784]）\n",
    "# dummy_input = torch.randn(1, 28 * 28)\n",
    "\n",
    "# # 导出模型到 ONNX 格式\n",
    "# torch.onnx.export(\n",
    "#     model,                # 要转换的模型\n",
    "#     dummy_input,          # 示例输入张量\n",
    "#     \"model.onnx\",         # 导出的 ONNX 文件名\n",
    "#     input_names=['input'],  # 输入张量的名称\n",
    "#     output_names=['output'],  # 输出张量的名称\n",
    "#     opset_version=11      # ONNX opset 版本，通常使用最新版本（这里使用 11）\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
